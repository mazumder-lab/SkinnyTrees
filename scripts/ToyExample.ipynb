{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4a6f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfef75b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0] linux /home/gridsan/shibal/.conda/envs/MOETF29/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd, numpy as np\n",
    "import timeit\n",
    "import joblib\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import pathlib\n",
    "sys.path.insert(0, os.getcwd().split('scripts')[0])\n",
    "\n",
    "print(sys.version, sys.platform, sys.executable) #Displays what environment you are actually using.\n",
    "\n",
    "from src import models\n",
    "from src import sparse_soft_trees\n",
    "from src import utils\n",
    "from data import data_utils\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "def get_available_cpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'CPU']\n",
    "\n",
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ee9a635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================num_classes: 2\n",
      "====================num_features: 30\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "seed = 8\n",
    "x_train_valid, x_test, y_train_valid, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=seed)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_valid, y_train_valid, test_size=0.2, stratify=y_train_valid, random_state=seed)\n",
    "\n",
    "assert len(y.shape)==1\n",
    "# print(\"Class-set (Train)\", np.unique(data_processed.y_train_processed))\n",
    "# print(\"Class-set (Valid)\", np.unique(data_processed.y_valid_processed))\n",
    "# print(\"Class-set (Train-Valid)\", np.unique(data_processed.y_train_valid_processed))\n",
    "# print(\"Class-set (Test)\", np.unique(data_processed.y_test_processed))\n",
    "num_classes = y.max(axis=0)+1\n",
    "print(\"====================num_classes:\", num_classes)\n",
    "num_features = x.shape[1]\n",
    "print(\"====================num_features:\", num_features)\n",
    "\n",
    "x_preprocessor = StandardScaler()\n",
    "x_train_processed = x_preprocessor.fit_transform(x_train)\n",
    "x_valid_processed = x_preprocessor.transform(x_valid)\n",
    "x_test_processed = x_preprocessor.transform(x_test)\n",
    "\n",
    "y_train_processed = y_train\n",
    "y_valid_processed = y_valid\n",
    "y_test_processed = y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc26b5",
   "metadata": {},
   "source": [
    "# Note \n",
    "\n",
    "Note that there are two configurations:\n",
    "1. Fixed Group-L0 regularization:\n",
    "use_annealing=False, kernel_constraint=varied across a range of params, number of epochs influence the degree of sparsity.\n",
    "2. Anneals the Group-L0 regularization:\n",
    "use_annealing=True, kernel_constraint=100, temperature = 0.01, epochs influence the degree of sparsity in the model\n",
    "\n",
    "Below we show running the model with a particular choice of hyperparameters for case (2). \n",
    "\n",
    "Since we solve the unconstrained feature selection problem, we need to sweep these parameters to find settings where the model the satisfies a desired budget of features. See main_classification_public_data.py for hyperparameter tuning with optuna and SkinnyTrees-Results.ipynb can be used to compile results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2d07a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============No LR scheduler, Epochs: 1000 Batch-size: 16\n",
      "==============epochs: 1000\n",
      "===========kernel_regularizer: <keras.regularizers.L2 object at 0x7f3d0c448b20>\n",
      "===========kernel_constraint: <src.sparse_soft_trees.ProximalGroupL0 object at 0x7f3d0c448af0>\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 30)]              0         \n",
      "                                                                 \n",
      " model_6 (Functional)        (None, 2)                 9940      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,940\n",
      "Trainable params: 9,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "23/23 [==============================] - 4s 29ms/step - loss: 0.4736 - accuracy: 0.8379 - lam: 0.3406 - nnz: 30.0000 - group-l0-reg: 10.2194 - val_loss: 0.3204 - val_accuracy: 0.9231 - val_lam: 0.6849 - val_nnz: 30.0000 - val_group-l0-reg: 20.5466\n",
      "Epoch 2/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2804 - accuracy: 0.9396 - lam: 0.9555 - nnz: 30.0000 - group-l0-reg: 28.6663 - val_loss: 0.2421 - val_accuracy: 0.9560 - val_lam: 1.2291 - val_nnz: 30.0000 - val_group-l0-reg: 36.8716\n",
      "Epoch 3/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2260 - accuracy: 0.9505 - lam: 1.4441 - nnz: 30.0000 - group-l0-reg: 43.3230 - val_loss: 0.2080 - val_accuracy: 0.9560 - val_lam: 1.6614 - val_nnz: 30.0000 - val_group-l0-reg: 49.8424\n",
      "Epoch 4/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1972 - accuracy: 0.9533 - lam: 1.8323 - nnz: 30.0000 - group-l0-reg: 54.9682 - val_loss: 0.1882 - val_accuracy: 0.9560 - val_lam: 2.0049 - val_nnz: 30.0000 - val_group-l0-reg: 60.1481\n",
      "Epoch 5/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1785 - accuracy: 0.9615 - lam: 2.1407 - nnz: 30.0000 - group-l0-reg: 64.2207 - val_loss: 0.1749 - val_accuracy: 0.9560 - val_lam: 2.2779 - val_nnz: 30.0000 - val_group-l0-reg: 68.3363\n",
      "Epoch 6/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1642 - accuracy: 0.9698 - lam: 2.3857 - nnz: 30.0000 - group-l0-reg: 71.5722 - val_loss: 0.1661 - val_accuracy: 0.9560 - val_lam: 2.4947 - val_nnz: 30.0000 - val_group-l0-reg: 74.8421\n",
      "Epoch 7/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1538 - accuracy: 0.9725 - lam: 2.5804 - nnz: 30.0000 - group-l0-reg: 77.4131 - val_loss: 0.1593 - val_accuracy: 0.9560 - val_lam: 2.6670 - val_nnz: 30.0000 - val_group-l0-reg: 80.0112\n",
      "Epoch 8/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1454 - accuracy: 0.9753 - lam: 2.7351 - nnz: 30.0000 - group-l0-reg: 82.0540 - val_loss: 0.1539 - val_accuracy: 0.9560 - val_lam: 2.8039 - val_nnz: 30.0000 - val_group-l0-reg: 84.1183\n",
      "Epoch 9/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1386 - accuracy: 0.9780 - lam: 2.8580 - nnz: 30.0000 - group-l0-reg: 85.7413 - val_loss: 0.1496 - val_accuracy: 0.9560 - val_lam: 2.9127 - val_nnz: 30.0000 - val_group-l0-reg: 87.3814\n",
      "Epoch 10/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1328 - accuracy: 0.9780 - lam: 2.9557 - nnz: 30.0000 - group-l0-reg: 88.6710 - val_loss: 0.1463 - val_accuracy: 0.9560 - val_lam: 2.9991 - val_nnz: 30.0000 - val_group-l0-reg: 89.9741\n",
      "Epoch 11/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1281 - accuracy: 0.9780 - lam: 3.0333 - nnz: 30.0000 - group-l0-reg: 90.9987 - val_loss: 0.1434 - val_accuracy: 0.9560 - val_lam: 3.0678 - val_nnz: 30.0000 - val_group-l0-reg: 92.0341\n",
      "Epoch 12/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1237 - accuracy: 0.9780 - lam: 3.0949 - nnz: 30.0000 - group-l0-reg: 92.8482 - val_loss: 0.1408 - val_accuracy: 0.9670 - val_lam: 3.1224 - val_nnz: 30.0000 - val_group-l0-reg: 93.6708\n",
      "Epoch 13/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.9808 - lam: 3.1439 - nnz: 30.0000 - group-l0-reg: 94.3176 - val_loss: 0.1387 - val_accuracy: 0.9670 - val_lam: 3.1657 - val_nnz: 30.0000 - val_group-l0-reg: 94.9713\n",
      "Epoch 14/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1167 - accuracy: 0.9808 - lam: 3.1828 - nnz: 30.0000 - group-l0-reg: 95.4852 - val_loss: 0.1369 - val_accuracy: 0.9670 - val_lam: 3.2001 - val_nnz: 30.0000 - val_group-l0-reg: 96.0045\n",
      "Epoch 15/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9808 - lam: 3.2138 - nnz: 30.0000 - group-l0-reg: 96.4128 - val_loss: 0.1352 - val_accuracy: 0.9670 - val_lam: 3.2275 - val_nnz: 30.0000 - val_group-l0-reg: 96.8254\n",
      "Epoch 16/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.9808 - lam: 3.2383 - nnz: 30.0000 - group-l0-reg: 97.1498 - val_loss: 0.1338 - val_accuracy: 0.9670 - val_lam: 3.2493 - val_nnz: 30.0000 - val_group-l0-reg: 97.4777\n",
      "Epoch 17/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9808 - lam: 3.2578 - nnz: 30.0000 - group-l0-reg: 97.7355 - val_loss: 0.1324 - val_accuracy: 0.9670 - val_lam: 3.2665 - val_nnz: 30.0000 - val_group-l0-reg: 97.9959\n",
      "Epoch 18/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1067 - accuracy: 0.9808 - lam: 3.2734 - nnz: 30.0000 - group-l0-reg: 98.2007 - val_loss: 0.1312 - val_accuracy: 0.9670 - val_lam: 3.2803 - val_nnz: 30.0000 - val_group-l0-reg: 98.4077\n",
      "Epoch 19/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9808 - lam: 3.2857 - nnz: 30.0000 - group-l0-reg: 98.5704 - val_loss: 0.1302 - val_accuracy: 0.9670 - val_lam: 3.2912 - val_nnz: 30.0000 - val_group-l0-reg: 98.7349\n",
      "Epoch 20/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.9835 - lam: 3.2955 - nnz: 30.0000 - group-l0-reg: 98.8642 - val_loss: 0.1293 - val_accuracy: 0.9670 - val_lam: 3.2998 - val_nnz: 30.0000 - val_group-l0-reg: 98.9948\n",
      "Epoch 21/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9835 - lam: 3.3033 - nnz: 30.0000 - group-l0-reg: 99.0975 - val_loss: 0.1285 - val_accuracy: 0.9670 - val_lam: 3.3067 - val_nnz: 30.0000 - val_group-l0-reg: 99.2013\n",
      "Epoch 22/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0997 - accuracy: 0.9835 - lam: 3.3094 - nnz: 30.0000 - group-l0-reg: 99.2830 - val_loss: 0.1277 - val_accuracy: 0.9670 - val_lam: 3.3122 - val_nnz: 30.0000 - val_group-l0-reg: 99.3654\n",
      "Epoch 23/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0986 - accuracy: 0.9835 - lam: 3.3143 - nnz: 30.0000 - group-l0-reg: 99.4303 - val_loss: 0.1270 - val_accuracy: 0.9670 - val_lam: 3.3165 - val_nnz: 30.0000 - val_group-l0-reg: 99.4958\n",
      "Epoch 24/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9835 - lam: 3.3182 - nnz: 30.0000 - group-l0-reg: 99.5473 - val_loss: 0.1264 - val_accuracy: 0.9670 - val_lam: 3.3200 - val_nnz: 30.0000 - val_group-l0-reg: 99.5994\n",
      "Epoch 25/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9835 - lam: 3.3213 - nnz: 30.0000 - group-l0-reg: 99.6404 - val_loss: 0.1258 - val_accuracy: 0.9670 - val_lam: 3.3227 - val_nnz: 30.0000 - val_group-l0-reg: 99.6817\n",
      "Epoch 26/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0947 - accuracy: 0.9835 - lam: 3.3238 - nnz: 30.0000 - group-l0-reg: 99.7142 - val_loss: 0.1253 - val_accuracy: 0.9670 - val_lam: 3.3249 - val_nnz: 30.0000 - val_group-l0-reg: 99.7471\n",
      "Epoch 27/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0937 - accuracy: 0.9835 - lam: 3.3258 - nnz: 30.0000 - group-l0-reg: 99.7730 - val_loss: 0.1248 - val_accuracy: 0.9670 - val_lam: 3.3266 - val_nnz: 30.0000 - val_group-l0-reg: 99.7991\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0926 - accuracy: 0.9835 - lam: 3.3273 - nnz: 30.0000 - group-l0-reg: 99.8196 - val_loss: 0.1244 - val_accuracy: 0.9670 - val_lam: 3.3280 - val_nnz: 30.0000 - val_group-l0-reg: 99.8404\n",
      "Epoch 29/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9835 - lam: 3.3286 - nnz: 30.0000 - group-l0-reg: 99.8567 - val_loss: 0.1240 - val_accuracy: 0.9670 - val_lam: 3.3291 - val_nnz: 30.0000 - val_group-l0-reg: 99.8732\n",
      "Epoch 30/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9835 - lam: 3.3295 - nnz: 30.0000 - group-l0-reg: 99.8861 - val_loss: 0.1236 - val_accuracy: 0.9670 - val_lam: 3.3300 - val_nnz: 30.0000 - val_group-l0-reg: 99.8992\n",
      "Epoch 31/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0899 - accuracy: 0.9863 - lam: 3.3303 - nnz: 30.0000 - group-l0-reg: 99.9095 - val_loss: 0.1232 - val_accuracy: 0.9670 - val_lam: 3.3307 - val_nnz: 30.0000 - val_group-l0-reg: 99.9199\n",
      "Epoch 32/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9863 - lam: 3.3309 - nnz: 30.0000 - group-l0-reg: 99.9281 - val_loss: 0.1229 - val_accuracy: 0.9670 - val_lam: 3.3312 - val_nnz: 30.0000 - val_group-l0-reg: 99.9364\n",
      "Epoch 33/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9863 - lam: 3.3314 - nnz: 30.0000 - group-l0-reg: 99.9429 - val_loss: 0.1226 - val_accuracy: 0.9670 - val_lam: 3.3316 - val_nnz: 30.0000 - val_group-l0-reg: 99.9495\n",
      "Epoch 34/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9863 - lam: 3.3318 - nnz: 30.0000 - group-l0-reg: 99.9546 - val_loss: 0.1223 - val_accuracy: 0.9670 - val_lam: 3.3320 - val_nnz: 30.0000 - val_group-l0-reg: 99.9598\n",
      "Epoch 35/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9863 - lam: 3.3321 - nnz: 30.0000 - group-l0-reg: 99.9639 - val_loss: 0.1221 - val_accuracy: 0.9670 - val_lam: 3.3323 - val_nnz: 30.0000 - val_group-l0-reg: 99.9681\n",
      "Epoch 36/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9863 - lam: 3.3324 - nnz: 30.0000 - group-l0-reg: 99.9714 - val_loss: 0.1218 - val_accuracy: 0.9670 - val_lam: 3.3325 - val_nnz: 30.0000 - val_group-l0-reg: 99.9746\n",
      "Epoch 37/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9863 - lam: 3.3326 - nnz: 30.0000 - group-l0-reg: 99.9772 - val_loss: 0.1216 - val_accuracy: 0.9670 - val_lam: 3.3327 - val_nnz: 30.0000 - val_group-l0-reg: 99.9799\n",
      "Epoch 38/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9863 - lam: 3.3327 - nnz: 30.0000 - group-l0-reg: 99.9819 - val_loss: 0.1214 - val_accuracy: 0.9670 - val_lam: 3.3328 - val_nnz: 30.0000 - val_group-l0-reg: 99.9840\n",
      "Epoch 39/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9863 - lam: 3.3329 - nnz: 30.0000 - group-l0-reg: 99.9856 - val_loss: 0.1212 - val_accuracy: 0.9670 - val_lam: 3.3329 - val_nnz: 30.0000 - val_group-l0-reg: 99.9873\n",
      "Epoch 40/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9863 - lam: 3.3330 - nnz: 30.0000 - group-l0-reg: 99.9886 - val_loss: 0.1210 - val_accuracy: 0.9670 - val_lam: 3.3330 - val_nnz: 30.0000 - val_group-l0-reg: 99.9899\n",
      "Epoch 41/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9863 - lam: 3.3330 - nnz: 30.0000 - group-l0-reg: 99.9909 - val_loss: 0.1208 - val_accuracy: 0.9670 - val_lam: 3.3331 - val_nnz: 30.0000 - val_group-l0-reg: 99.9920\n",
      "Epoch 42/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9890 - lam: 3.3331 - nnz: 30.0000 - group-l0-reg: 99.9928 - val_loss: 0.1207 - val_accuracy: 0.9670 - val_lam: 3.3331 - val_nnz: 30.0000 - val_group-l0-reg: 99.9936\n",
      "Epoch 43/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9863 - lam: 3.3331 - nnz: 30.0000 - group-l0-reg: 99.9943 - val_loss: 0.1205 - val_accuracy: 0.9670 - val_lam: 3.3332 - val_nnz: 30.0000 - val_group-l0-reg: 99.9949\n",
      "Epoch 44/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9890 - lam: 3.3332 - nnz: 30.0000 - group-l0-reg: 99.9954 - val_loss: 0.1204 - val_accuracy: 0.9670 - val_lam: 3.3332 - val_nnz: 30.0000 - val_group-l0-reg: 99.9960\n",
      "Epoch 45/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9863 - lam: 3.3332 - nnz: 30.0000 - group-l0-reg: 99.9964 - val_loss: 0.1202 - val_accuracy: 0.9670 - val_lam: 3.3332 - val_nnz: 30.0000 - val_group-l0-reg: 99.9968\n",
      "Epoch 46/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9890 - lam: 3.3332 - nnz: 30.0000 - group-l0-reg: 99.9971 - val_loss: 0.1200 - val_accuracy: 0.9670 - val_lam: 3.3332 - val_nnz: 30.0000 - val_group-l0-reg: 99.9975\n",
      "Epoch 47/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9863 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9977 - val_loss: 0.1199 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9980\n",
      "Epoch 48/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9982 - val_loss: 0.1198 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9984\n",
      "Epoch 49/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9986 - val_loss: 0.1197 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9987\n",
      "Epoch 50/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9989 - val_loss: 0.1196 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9990\n",
      "Epoch 51/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9991 - val_loss: 0.1195 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9992\n",
      "Epoch 52/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9993 - val_loss: 0.1195 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9994\n",
      "Epoch 53/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9994 - val_loss: 0.1194 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9995\n",
      "Epoch 54/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9995 - val_loss: 0.1193 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9996\n",
      "Epoch 55/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9996 - val_loss: 0.1192 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9997\n",
      "Epoch 56/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9997 - val_loss: 0.1191 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9997\n",
      "Epoch 57/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9998 - val_loss: 0.1190 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9998\n",
      "Epoch 58/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9998 - val_loss: 0.1189 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9998\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9999 - val_loss: 0.1188 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9999\n",
      "Epoch 60/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0757 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9999 - val_loss: 0.1187 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9999\n",
      "Epoch 61/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9999 - val_loss: 0.1187 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9999\n",
      "Epoch 62/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 99.9999 - val_loss: 0.1186 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9999\n",
      "Epoch 63/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1185 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9999\n",
      "Epoch 64/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0745 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1184 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 99.9999\n",
      "Epoch 65/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1184 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 66/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1183 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 67/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1181 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 68/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1180 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 69/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1180 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 70/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1180 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 71/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1179 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 72/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1179 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 73/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1179 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 74/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1179 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 75/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1177 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 76/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1176 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 77/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0712 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1176 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 78/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1176 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 79/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1176 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 80/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1175 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 81/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1174 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 82/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1174 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 83/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1173 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 84/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1173 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 85/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0696 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1173 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 86/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0693 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1172 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 87/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1171 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 88/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1170 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 89/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1170 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1170 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 91/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1170 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 92/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1169 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 93/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1168 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 94/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1168 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 95/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0676 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1167 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 96/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1167 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 97/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1166 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 98/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1166 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 99/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1166 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 100/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1165 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 101/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1164 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 102/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1164 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 103/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0664 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1164 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 104/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0662 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1164 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 105/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1163 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 106/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0659 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1164 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 107/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0657 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1163 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 108/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1163 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 109/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 110/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 111/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 112/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 113/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1160 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 114/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1160 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 115/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1159 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 116/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1159 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 117/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0643 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1160 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 118/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1159 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 119/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1158 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 120/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0639 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1158 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0637 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 122/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 123/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 124/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1155 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 125/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0631 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1155 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 126/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1155 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 127/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0629 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 128/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 129/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0627 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 130/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 131/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 132/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 133/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 134/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0620 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 135/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1152 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 136/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0618 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1152 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 137/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1151 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 138/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1151 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 139/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1151 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 140/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1151 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 141/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1150 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 142/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1150 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 143/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 144/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0608 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 145/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 146/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 147/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 148/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 149/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0603 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 150/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0603 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 151/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0600 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 152/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0599 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1147 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 153/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0598 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1147 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 154/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1146 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 155/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0596 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1146 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 156/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1146 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 157/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1145 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 158/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0593 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1145 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 159/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1144 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 160/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1143 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 161/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0589 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1143 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 162/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0589 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 163/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 164/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 165/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0585 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 166/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0584 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 167/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 168/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1140 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 169/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0581 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1140 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 170/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 171/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0579 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 172/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 173/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0577 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 174/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 175/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 176/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0574 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 177/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 178/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0571 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1137 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 179/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0571 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 180/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 181/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0568 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 182/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0567 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 183/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0568 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 184/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 185/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 186/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 187/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0563 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 188/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 189/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 190/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 191/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 192/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0559 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 193/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 194/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0557 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 195/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 196/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 197/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 198/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 199/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0552 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 200/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 201/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0550 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 202/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0549 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 203/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0548 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 204/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 205/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1125 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 206/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1125 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 207/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1125 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 208/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1125 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 209/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0543 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1124 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 210/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0542 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1124 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 211/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0542 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1124 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 212/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0540 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1124 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 213/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0539 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1124 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 214/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0539 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1124 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 215/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1124 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 216/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1123 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 217/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0536 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1123 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 218/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0535 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1123 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 219/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0534 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1122 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 220/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0533 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1121 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 221/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0533 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1122 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 222/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0532 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1121 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 223/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0531 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 224/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0531 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1123 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 225/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 226/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 227/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 228/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1121 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 229/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1120 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 230/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0524 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1120 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 231/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0524 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1120 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 232/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0524 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1119 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 233/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1119 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 234/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1119 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 235/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0521 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1119 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 236/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1119 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 237/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1119 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 238/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1119 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 239/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1119 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 240/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1117 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 241/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1117 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 242/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1117 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 243/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1116 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 244/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1117 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 245/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1116 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 246/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1116 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 247/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1117 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 248/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0510 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1117 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 249/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1116 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 250/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0509 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1116 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 251/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1116 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 252/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 253/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 254/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0506 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 255/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9780 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 256/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 257/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 258/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 259/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 260/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1115 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 261/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1114 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 262/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0500 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1114 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 263/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 264/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0499 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1114 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 265/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 266/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 267/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 268/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 269/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 270/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 271/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 272/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 273/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 274/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 275/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0489 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 277/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 278/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 279/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 280/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 281/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 282/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 283/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 284/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 285/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0483 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 286/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 287/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 288/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 289/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 290/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 291/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 292/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 293/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 294/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 295/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 296/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 297/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 298/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 299/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 300/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0473 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 301/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0472 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 302/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0472 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 303/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0471 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 304/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 305/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 306/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 307/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 308/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 309/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 310/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0466 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 311/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 312/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 313/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 314/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1106 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 315/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0462 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1107 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 316/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1107 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 317/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1106 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 318/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1106 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 319/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0460 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1106 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 320/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0460 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1107 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 321/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1107 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 322/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1107 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 323/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 324/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 325/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 326/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 327/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0455 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 328/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 329/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 330/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 331/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 332/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0452 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 333/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 334/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 335/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 336/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 337/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 338/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 339/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 340/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 341/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 342/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 343/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 344/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 345/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 346/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 347/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 348/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 349/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0441 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 350/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 351/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 352/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 353/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 354/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 355/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1107 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 356/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 357/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1107 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 358/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1107 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 359/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 360/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 361/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 362/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0433 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 363/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 364/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 365/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 366/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 367/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 368/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 370/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 371/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 372/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 373/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 374/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0427 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 375/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1108 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 376/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 377/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1109 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 378/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1110 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 379/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0423 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 380/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0423 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 381/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 382/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 383/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0421 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 384/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0420 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 385/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0420 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 386/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0420 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 387/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1113 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 388/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 389/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 390/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 391/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1111 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 392/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 393/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9945 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1112 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 30.0000 - val_group-l0-reg: 100.0000\n",
      "Epoch 394/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9918 - lam: 3.3333 - nnz: 30.0000 - group-l0-reg: 100.0000 - val_loss: 0.1123 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 395/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 396/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1123 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 397/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1123 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 398/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 399/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1121 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 401/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1121 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 402/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1121 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 403/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1121 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 404/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1121 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 405/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0408 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1121 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 406/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1121 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 407/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0407 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 408/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 409/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0406 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1122 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 410/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1123 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 411/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0405 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1123 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 412/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0405 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1124 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 413/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0404 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1124 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 414/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1124 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 415/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1123 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 416/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1124 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 417/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1123 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 418/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1124 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 419/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1124 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 420/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1124 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 421/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1125 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 422/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1125 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 423/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1126 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 424/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1127 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 425/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1124 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 426/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1125 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 427/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1125 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 428/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1125 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 429/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1126 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 430/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1126 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 431/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1127 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 432/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 433/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1125 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 434/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1126 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 435/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0393 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1126 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 436/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1127 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 437/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1127 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 438/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 439/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1128 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 440/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9918 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 441/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 442/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 443/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 444/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 445/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 446/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0388 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 447/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0387 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 448/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9945 - lam: 3.3333 - nnz: 29.0000 - group-l0-reg: 96.6666 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 29.0000 - val_group-l0-reg: 96.6667\n",
      "Epoch 449/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.2609 - group-l0-reg: 94.2029 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 450/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 451/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0386 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 452/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 453/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 454/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0384 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 455/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 456/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0383 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 457/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1137 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 458/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 459/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 460/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 461/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 462/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1137 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 463/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 464/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 465/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 466/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 467/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 468/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1140 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 469/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 470/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9945 - lam: 3.3333 - nnz: 28.0000 - group-l0-reg: 93.3333 - val_loss: 0.1143 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 28.0000 - val_group-l0-reg: 93.3333\n",
      "Epoch 471/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.7391 - group-l0-reg: 92.4638 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 472/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 473/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 474/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 475/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 476/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1137 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 477/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 478/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0375 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 479/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0374 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1137 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 480/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 481/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 482/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 483/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1140 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 484/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 485/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 486/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 487/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 488/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 489/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1143 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 490/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1143 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 491/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1144 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 492/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1145 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1145 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 494/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1144 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 495/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1145 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 496/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1145 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 497/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 498/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 499/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 500/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 501/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 502/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 503/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 504/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 505/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 506/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 507/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1150 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 508/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1151 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 509/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1151 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 510/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1151 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 511/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1152 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 512/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 513/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 514/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 515/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 516/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0359 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 517/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1155 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 518/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1155 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 519/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1155 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 520/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1155 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 521/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1156 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 522/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1156 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 523/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 524/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 525/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 526/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 527/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1158 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 528/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1158 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 529/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1159 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 530/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1160 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 531/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1160 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 532/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 533/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 534/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 535/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0351 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 536/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 537/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 538/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1163 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 539/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 540/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 541/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 542/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9945 - lam: 3.3333 - nnz: 27.0000 - group-l0-reg: 90.0000 - val_loss: 0.1163 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 27.0000 - val_group-l0-reg: 90.0000\n",
      "Epoch 543/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.6522 - group-l0-reg: 88.8406 - val_loss: 0.1144 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 544/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1143 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 545/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 546/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 547/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 548/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0351 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 549/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 550/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1137 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 551/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 552/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 553/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 554/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9918 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 555/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 556/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 557/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 558/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 559/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 560/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 561/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 562/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1129 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 563/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 564/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 565/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1130 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 566/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 567/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 568/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 569/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 570/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 571/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 572/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1131 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 573/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 574/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 575/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 576/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 577/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 578/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 579/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 580/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 581/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 582/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 583/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 584/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 585/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 586/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 587/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 588/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1132 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 589/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1133 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 590/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 591/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 592/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1134 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 593/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 594/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 595/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 596/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 597/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 598/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 599/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 600/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 601/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 602/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1135 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 603/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 604/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1136 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 605/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1137 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 606/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1137 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 607/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 608/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 609/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1138 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 610/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1139 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 611/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1140 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 612/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1140 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 613/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1140 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 614/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1140 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 615/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 616/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 618/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1141 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 619/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 620/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 621/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1143 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 622/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9945 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1144 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 623/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1144 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 624/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1142 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 625/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1144 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 626/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1143 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 627/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1145 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 628/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1145 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 629/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 630/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 631/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 632/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1148 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 633/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1149 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 634/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1150 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 635/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1150 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 636/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1150 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 637/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1151 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 638/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1152 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 639/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1152 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 640/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 641/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 642/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 643/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 644/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 645/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1153 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 646/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 647/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1154 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 648/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1155 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 649/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1156 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 650/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1156 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 651/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1156 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 652/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 653/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 654/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1157 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 655/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1159 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 656/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1159 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 657/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 658/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1160 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 659/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 660/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 661/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 662/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 663/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 664/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 665/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 666/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 667/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 668/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1161 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 669/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 670/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1162 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 671/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1163 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 672/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1163 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 673/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1164 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 674/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1164 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 675/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1165 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 676/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1165 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 677/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1165 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 678/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1166 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 679/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1167 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 680/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1167 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 681/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1167 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 682/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1168 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 683/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1169 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 684/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1170 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 685/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1171 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 686/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1171 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 687/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1172 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 688/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1172 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 689/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1173 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 690/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1174 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 691/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1174 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 692/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1174 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 693/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1174 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 694/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1175 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 695/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1175 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 696/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1176 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 697/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1176 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 698/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1177 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 699/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1177 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 700/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1178 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 701/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1177 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 702/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1177 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 703/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1177 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 704/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1178 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 705/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1179 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 706/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1179 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 707/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1180 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 708/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1182 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 709/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1181 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1182 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 711/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1182 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 712/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1181 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 713/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1181 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 714/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1182 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 715/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1182 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 716/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1181 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 717/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1182 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 718/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1184 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 719/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1186 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 720/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1186 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 721/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1186 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 722/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1187 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 723/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1188 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 724/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1188 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 725/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1188 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 726/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1187 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 727/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1188 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 728/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1189 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 729/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1189 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 730/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1191 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 731/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1192 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 732/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1192 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 733/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1192 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 734/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1194 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 735/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1193 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 736/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1193 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 737/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1193 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 738/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1194 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 739/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1194 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 740/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1195 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 741/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1195 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 742/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1195 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 743/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1196 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 744/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1197 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 745/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1197 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 746/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1198 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 747/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1198 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 748/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1199 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 749/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1199 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 750/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1199 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 751/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1200 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 752/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1200 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 753/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1201 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 754/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1201 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 755/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1202 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 756/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1202 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 757/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1203 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 758/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1202 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 759/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1203 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 760/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1203 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 761/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1205 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 762/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1205 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 763/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1206 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 764/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1206 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 765/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1207 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 766/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1208 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 767/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0285 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1208 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 768/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1209 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 769/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1209 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 770/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1207 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 771/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0285 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1207 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1207 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 773/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1207 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 774/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0283 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1207 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 775/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0283 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1208 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 776/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1208 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 777/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1210 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 778/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1210 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 779/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1210 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 780/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1210 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 781/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1211 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 782/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1212 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 783/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1213 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 784/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1213 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 785/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1213 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 786/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1211 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 787/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1211 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 788/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1212 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 789/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1211 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 790/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1212 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 791/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1212 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 792/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1213 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 793/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1214 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 794/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1215 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 795/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1215 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 796/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1215 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 797/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1216 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 798/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1217 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 799/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1218 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 800/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1218 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 801/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1219 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 802/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1219 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 803/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1219 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 804/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1219 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 805/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1220 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 806/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1220 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 807/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1220 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 808/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1221 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 809/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1219 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 810/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1220 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 811/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1221 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 812/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0275 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1221 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 813/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1222 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 814/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1222 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 815/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1222 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 816/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1223 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 817/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1223 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 818/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1222 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 819/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1222 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 820/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1223 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 821/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1224 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 822/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1225 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 823/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1225 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 824/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1225 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 825/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1227 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 826/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1228 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 827/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1228 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 828/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1228 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 829/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1228 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 830/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1228 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 831/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1229 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 832/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1228 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 833/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9973 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1228 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1229 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 835/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1229 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 836/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1231 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 837/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1231 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 838/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1232 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 839/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1232 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 840/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1233 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 841/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1232 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 842/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1233 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 843/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1233 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 844/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1233 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 845/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1233 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 846/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1233 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 847/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1232 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 848/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1234 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 849/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1234 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 850/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0268 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1232 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 851/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1234 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 852/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1234 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 853/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1234 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 854/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1235 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 855/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1236 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 856/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1237 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 857/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1237 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 858/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1237 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 859/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1237 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 860/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1238 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 861/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1238 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 862/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1239 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 863/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1238 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 864/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1239 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1241 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 866/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1242 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 867/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1242 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 868/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1242 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 869/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1243 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 870/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1244 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 871/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1245 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 872/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1244 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 873/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1245 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 874/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1245 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 875/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1245 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 876/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1246 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 877/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1246 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 878/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1247 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 879/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1247 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 880/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1248 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 881/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1247 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 882/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1247 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 883/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1248 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 884/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1248 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 885/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1248 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 886/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1248 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 887/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1248 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 888/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1249 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 889/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1248 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 890/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1249 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 891/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1249 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 892/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1250 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 893/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1250 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 894/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1251 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 895/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1252 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1251 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 897/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1252 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 898/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1253 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 899/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1253 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 900/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1253 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 901/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1252 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 902/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1254 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 903/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1254 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 904/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1254 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 905/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1255 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 906/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1256 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 907/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1257 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 908/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1257 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 909/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1256 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 910/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1257 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 911/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1257 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 912/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1258 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 913/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1258 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 914/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1258 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 915/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1258 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 916/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1258 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 917/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1258 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 918/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1259 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 919/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1258 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 920/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1260 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 921/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1260 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 922/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1260 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 923/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1260 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 924/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1261 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 925/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1261 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 926/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1261 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 927/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1262 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 928/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1262 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 929/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1263 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 930/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1263 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 931/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1263 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 932/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1264 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 933/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1264 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 934/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1265 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 935/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1266 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 936/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1267 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 937/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1267 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 938/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1265 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 939/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1265 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 940/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1265 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 941/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1265 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 942/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1265 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 943/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1265 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 944/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1265 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 945/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1266 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 946/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1267 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 947/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1267 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 948/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1267 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 949/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1268 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 950/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1269 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 951/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1269 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 952/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1270 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 953/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1270 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 954/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1271 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 955/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1272 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 956/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1271 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 957/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1269 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 958/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1269 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 959/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1270 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 960/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1271 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 961/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1272 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 962/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1272 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 963/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1272 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 964/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1273 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 965/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1274 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 966/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1274 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 967/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1274 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 968/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1275 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 969/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1275 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 970/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1275 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 971/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1275 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 972/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 973/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 974/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 975/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 976/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 977/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 978/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 979/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 980/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 981/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 982/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1277 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 983/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1276 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 984/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1277 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 985/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1277 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 986/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1277 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 987/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1277 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 988/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1278 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 989/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1278 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 990/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1279 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 991/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1280 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 992/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1280 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 993/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1280 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 994/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1279 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 995/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1279 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 996/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1279 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 997/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1280 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 998/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1280 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 999/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1280 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "Epoch 1000/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 1.0000 - lam: 3.3333 - nnz: 26.0000 - group-l0-reg: 86.6666 - val_loss: 0.1280 - val_accuracy: 0.9670 - val_lam: 3.3333 - val_nnz: 26.0000 - val_group-l0-reg: 86.6667\n",
      "============best_epoch: 1000\n",
      "============number_of_epochs_it_ran: 1000\n",
      "3/3 [==============================] - 1s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "accuracy (valid): 0.967032967032967\n",
      "accuracy (test): 0.9912280701754386\n",
      "auc (valid): 0.9896800825593395\n",
      "auc (test): 0.9993386243386243\n",
      "num_epochs 1000\n",
      "val_loss_history [0.3203698992729187, 0.2420951873064041, 0.20800445973873138, 0.18819361925125122, 0.17491285502910614, 0.1660512387752533, 0.15932387113571167, 0.15391696989536285, 0.1496189385652542, 0.14630751311779022, 0.14340434968471527, 0.14081794023513794, 0.1387106031179428, 0.13686326146125793, 0.13519132137298584, 0.13377749919891357, 0.13243024051189423, 0.13117848336696625, 0.1302054524421692, 0.1292586773633957, 0.1285146325826645, 0.12774591147899628, 0.12698383629322052, 0.12637989223003387, 0.12584027647972107, 0.12531022727489471, 0.12482816725969315, 0.12439317256212234, 0.1239967942237854, 0.12361395359039307, 0.12324972450733185, 0.12292168289422989, 0.12264404445886612, 0.1223306953907013, 0.12207680940628052, 0.12179751694202423, 0.12158001959323883, 0.12139180302619934, 0.12121942639350891, 0.12097965180873871, 0.12083881348371506, 0.12070103734731674, 0.12052607536315918, 0.12035692483186722, 0.12022650241851807, 0.1200486570596695, 0.11990147829055786, 0.11980719864368439, 0.1196974590420723, 0.11959344148635864, 0.11950613558292389, 0.11952364444732666, 0.11942288279533386, 0.11932653933763504, 0.11922768503427505, 0.1191166490316391, 0.11900019645690918, 0.11887723207473755, 0.1187940314412117, 0.11872398108243942, 0.11865837872028351, 0.11859502643346786, 0.11851733922958374, 0.11842641979455948, 0.11835508793592453, 0.11825695633888245, 0.11810271441936493, 0.1180364191532135, 0.11804983019828796, 0.11796709150075912, 0.11791948974132538, 0.11786025762557983, 0.1178511306643486, 0.11785218864679337, 0.11768435686826706, 0.11760887503623962, 0.11764168739318848, 0.11762207001447678, 0.11757595837116241, 0.11751548200845718, 0.1174250990152359, 0.11735627055168152, 0.11732491105794907, 0.11729441583156586, 0.11725122481584549, 0.11718929558992386, 0.1171286478638649, 0.1170399859547615, 0.11698606610298157, 0.11697607487440109, 0.11696790158748627, 0.1168898195028305, 0.11684541404247284, 0.11677633225917816, 0.11670321971178055, 0.11667682230472565, 0.11661028861999512, 0.11659151315689087, 0.11655529588460922, 0.11652818322181702, 0.11642871052026749, 0.11641783267259598, 0.11637210100889206, 0.11636855453252792, 0.11633239686489105, 0.11640948802232742, 0.11634385585784912, 0.11630300432443619, 0.11624108999967575, 0.1162385642528534, 0.11620781570672989, 0.11613576859235764, 0.11604735255241394, 0.11599841713905334, 0.11591237783432007, 0.11590663343667984, 0.11595329642295837, 0.11588840931653976, 0.11581011861562729, 0.11576719582080841, 0.11570781469345093, 0.11570028215646744, 0.11567360162734985, 0.11552710086107254, 0.11551447212696075, 0.11545361578464508, 0.11542657017707825, 0.11539340764284134, 0.11539813131093979, 0.11532171815633774, 0.11525873839855194, 0.11533132195472717, 0.11527218669652939, 0.1152656078338623, 0.11522722989320755, 0.11519774049520493, 0.11514544486999512, 0.1150914803147316, 0.11507045477628708, 0.11506526172161102, 0.1150219589471817, 0.11498430371284485, 0.11494793742895126, 0.11490430682897568, 0.11490144580602646, 0.11491746455430984, 0.114865243434906, 0.1148107573390007, 0.11479281634092331, 0.11479157954454422, 0.11476701498031616, 0.11469539254903793, 0.11468680948019028, 0.114619180560112, 0.11456507444381714, 0.11458618938922882, 0.11451054364442825, 0.11447003483772278, 0.11438673734664917, 0.1143241748213768, 0.11429359018802643, 0.11421656608581543, 0.11418772488832474, 0.11416234821081161, 0.11408806592226028, 0.11411406844854355, 0.11405491828918457, 0.11402714997529984, 0.11395619809627533, 0.11392806470394135, 0.11382725834846497, 0.11384716629981995, 0.11389455944299698, 0.11386948823928833, 0.11384227126836777, 0.11377029865980148, 0.11377447098493576, 0.11370135098695755, 0.11360297352075577, 0.11352115869522095, 0.1134621649980545, 0.11337005347013474, 0.11332417279481888, 0.11330565065145493, 0.1132737472653389, 0.11322571337223053, 0.11321193724870682, 0.11311910301446915, 0.11305800825357437, 0.11306177824735641, 0.11306466907262802, 0.1129988580942154, 0.1129746288061142, 0.11294297873973846, 0.11296325922012329, 0.11294594407081604, 0.11291970312595367, 0.11284979432821274, 0.11285733431577682, 0.11284779012203217, 0.11281172931194305, 0.11275394260883331, 0.11279195547103882, 0.11277353018522263, 0.11250767111778259, 0.11252034455537796, 0.11246886849403381, 0.11246167868375778, 0.11241323500871658, 0.11235788464546204, 0.11236894875764847, 0.112390898168087, 0.1123911440372467, 0.11236293613910675, 0.11236690729856491, 0.1123092770576477, 0.11229262501001358, 0.1122567281126976, 0.11215560138225555, 0.1121368333697319, 0.11217129975557327, 0.11214961856603622, 0.11221116781234741, 0.1122971847653389, 0.11224373430013657, 0.11219936609268188, 0.11215201765298843, 0.11210697144269943, 0.11202726513147354, 0.11202975362539291, 0.1119736060500145, 0.1119365245103836, 0.11192493885755539, 0.11187073588371277, 0.11189468950033188, 0.11190497130155563, 0.11189434677362442, 0.11188316345214844, 0.11185723543167114, 0.11174813657999039, 0.11171833425760269, 0.11173028498888016, 0.11163485050201416, 0.11166714876890182, 0.11160152405500412, 0.11161284148693085, 0.11169985681772232, 0.11174095422029495, 0.11164583265781403, 0.11158040165901184, 0.1115553230047226, 0.11149995774030685, 0.11152073740959167, 0.11149287968873978, 0.11147618293762207, 0.11150285601615906, 0.11147446930408478, 0.111460842192173, 0.11147721111774445, 0.1114502027630806, 0.11142915487289429, 0.11136320978403091, 0.11134623736143112, 0.1113630160689354, 0.11131538450717926, 0.11130814254283905, 0.11129104346036911, 0.11128038167953491, 0.11124010384082794, 0.11122036725282669, 0.11127287149429321, 0.11125044524669647, 0.11120633035898209, 0.11121878772974014, 0.11124304682016373, 0.1111745834350586, 0.11128880083560944, 0.11127875745296478, 0.11123064160346985, 0.11122272908687592, 0.11116481572389603, 0.1111898347735405, 0.11114631593227386, 0.11111827194690704, 0.11112964898347855, 0.11113718152046204, 0.11109904199838638, 0.11119340360164642, 0.11116020381450653, 0.11110387742519379, 0.11098086088895798, 0.11100366711616516, 0.11095689237117767, 0.11095830798149109, 0.11105377972126007, 0.11102867126464844, 0.11103759706020355, 0.11105486750602722, 0.11113187670707703, 0.11111447960138321, 0.11103180795907974, 0.1110042929649353, 0.11106088757514954, 0.11080963164567947, 0.11082564294338226, 0.11085156351327896, 0.11082829535007477, 0.11085852980613708, 0.11087505519390106, 0.1108073964715004, 0.1108386293053627, 0.11084838211536407, 0.11078467965126038, 0.11060282588005066, 0.11065542697906494, 0.1106528788805008, 0.11059557646512985, 0.11064659059047699, 0.11063481122255325, 0.11070404201745987, 0.11071299761533737, 0.11072462797164917, 0.1108187586069107, 0.11088575422763824, 0.1108475774526596, 0.11084239929914474, 0.1108095571398735, 0.11084610223770142, 0.11106917262077332, 0.11099555343389511, 0.11096444725990295, 0.11094850301742554, 0.11097610741853714, 0.11104516685009003, 0.11095747351646423, 0.11095649749040604, 0.11105473339557648, 0.11105030030012131, 0.11101607233285904, 0.11092887818813324, 0.11090699583292007, 0.11089655011892319, 0.11088912189006805, 0.11095269024372101, 0.1110282838344574, 0.11100033670663834, 0.11095255613327026, 0.110967256128788, 0.1109234094619751, 0.11103233695030212, 0.11099562793970108, 0.11101661622524261, 0.11092234402894974, 0.1108948215842247, 0.11071333289146423, 0.11078488826751709, 0.11071444302797318, 0.1107146367430687, 0.1107659786939621, 0.11080342531204224, 0.11079710721969604, 0.1108734980225563, 0.11091252416372299, 0.11090674996376038, 0.11091987788677216, 0.11089438199996948, 0.11098005622625351, 0.11096866428852081, 0.11093959957361221, 0.11102434992790222, 0.11083827167749405, 0.1109628975391388, 0.1107933521270752, 0.11083182692527771, 0.11083532869815826, 0.11091825366020203, 0.11093588173389435, 0.11098620295524597, 0.11108874529600143, 0.11127578467130661, 0.11126907169818878, 0.11120094358921051, 0.11122167110443115, 0.11120915412902832, 0.11126121878623962, 0.11124953627586365, 0.11128325015306473, 0.11105678975582123, 0.11107055842876434, 0.11111313849687576, 0.11107152700424194, 0.1111520379781723, 0.11121726781129837, 0.11226865649223328, 0.11224966496229172, 0.11226053535938263, 0.11225218325853348, 0.11217333376407623, 0.11212408542633057, 0.1121741384267807, 0.11214722692966461, 0.11209354549646378, 0.11213325709104538, 0.11211307346820831, 0.11211024224758148, 0.11208969354629517, 0.1121666431427002, 0.11215132474899292, 0.11224444955587387, 0.1122734397649765, 0.11233705282211304, 0.11238711327314377, 0.11242636293172836, 0.11236471682786942, 0.11233433336019516, 0.11235219240188599, 0.11234387010335922, 0.11238257586956024, 0.11242201924324036, 0.11244729906320572, 0.11247946321964264, 0.11250702291727066, 0.11260904371738434, 0.1126508116722107, 0.11242768168449402, 0.1124565526843071, 0.11246905475854874, 0.11250119656324387, 0.11258181929588318, 0.1126302182674408, 0.11268621683120728, 0.11277557909488678, 0.112497977912426, 0.1125648021697998, 0.11264996230602264, 0.1127399429678917, 0.11273938417434692, 0.11278098076581955, 0.11284858733415604, 0.11289789527654648, 0.11295148730278015, 0.11298396438360214, 0.11306930333375931, 0.11304687708616257, 0.11310583353042603, 0.11309734731912613, 0.11312299966812134, 0.11286520957946777, 0.11343763023614883, 0.11317861080169678, 0.11300496757030487, 0.11316011101007462, 0.11330346763134003, 0.11339610815048218, 0.11354417353868484, 0.11364671587944031, 0.11372145265340805, 0.11381523311138153, 0.11383930593729019, 0.1138957291841507, 0.11393318325281143, 0.11370348930358887, 0.11380677670240402, 0.11391077935695648, 0.11409852653741837, 0.11420891433954239, 0.11393596231937408, 0.11402182281017303, 0.1141306459903717, 0.1143384650349617, 0.11320663243532181, 0.11336833983659744, 0.11356712877750397, 0.11378170549869537, 0.11363431811332703, 0.1137021854519844, 0.1135498508810997, 0.11363591253757477, 0.11373761296272278, 0.11378105729818344, 0.11383403837680817, 0.1139335036277771, 0.11396240442991257, 0.11408637464046478, 0.11415358632802963, 0.11417636275291443, 0.11421897262334824, 0.11420692503452301, 0.11425533890724182, 0.11426015943288803, 0.11439428478479385, 0.11449914425611496, 0.1144513487815857, 0.11443746089935303, 0.11453408747911453, 0.11452848464250565, 0.11479081958532333, 0.1148543730378151, 0.11485794931650162, 0.11482984572649002, 0.11484218388795853, 0.11485385149717331, 0.11487800627946854, 0.11486726254224777, 0.11488419026136398, 0.11490713804960251, 0.11502737551927567, 0.11506841331720352, 0.11513678729534149, 0.11511233448982239, 0.1152314841747284, 0.115259550511837, 0.11530037969350815, 0.11536967009305954, 0.11541543900966644, 0.11544078588485718, 0.11553680151700974, 0.1155153438448906, 0.1154765635728836, 0.11549115180969238, 0.11560334265232086, 0.11558528244495392, 0.11565396934747696, 0.11566723138093948, 0.11569320410490036, 0.11573753505945206, 0.11578673869371414, 0.11584354192018509, 0.11594681441783905, 0.11602090299129486, 0.11603621393442154, 0.11610961705446243, 0.11613088846206665, 0.11612209677696228, 0.11611012369394302, 0.11619573831558228, 0.11619637906551361, 0.11627483367919922, 0.11623184382915497, 0.11623331159353256, 0.11622712761163712, 0.11627821624279022, 0.11440915614366531, 0.11430981755256653, 0.11419728398323059, 0.11412457376718521, 0.11390437930822372, 0.11384572088718414, 0.11378549039363861, 0.11370448023080826, 0.11360443383455276, 0.11355254054069519, 0.11354528367519379, 0.11352419853210449, 0.1134352833032608, 0.1133064553141594, 0.11304046213626862, 0.11307365447282791, 0.11288683861494064, 0.11294004321098328, 0.11290263384580612, 0.11289995163679123, 0.11296460777521133, 0.1129501685500145, 0.11297305673360825, 0.11314943432807922, 0.11312428116798401, 0.11316351592540741, 0.11315345019102097, 0.11315874755382538, 0.11312933266162872, 0.11313112825155258, 0.11334189772605896, 0.11336429417133331, 0.11325942724943161, 0.11332656443119049, 0.11333182454109192, 0.11335150897502899, 0.1133665218949318, 0.11337270587682724, 0.11339780688285828, 0.11332865059375763, 0.11337386816740036, 0.11319451779127121, 0.11319132894277573, 0.11318036168813705, 0.11320139467716217, 0.11324954777956009, 0.11331357806921005, 0.11343458294868469, 0.11343599855899811, 0.11338401585817337, 0.11347133666276932, 0.11348031461238861, 0.11350726336240768, 0.11360689997673035, 0.11360493302345276, 0.11356206983327866, 0.11352834850549698, 0.11357463896274567, 0.11354409903287888, 0.1135450080037117, 0.11363955587148666, 0.11362436413764954, 0.11373408883810043, 0.113726407289505, 0.11379295587539673, 0.11377482116222382, 0.11380865424871445, 0.11387163400650024, 0.11397148668766022, 0.11402226239442825, 0.11404955387115479, 0.1140478253364563, 0.11410931497812271, 0.11409080773591995, 0.11417979747056961, 0.11410373449325562, 0.11416414380073547, 0.11424858123064041, 0.1143193393945694, 0.11436225473880768, 0.11438307166099548, 0.1141786053776741, 0.11444634944200516, 0.114341139793396, 0.1144542396068573, 0.11449426412582397, 0.1147790253162384, 0.11476679891347885, 0.11480898410081863, 0.11483827233314514, 0.1149054616689682, 0.11499420553445816, 0.11502450704574585, 0.11501085013151169, 0.11511067301034927, 0.11520501226186752, 0.1151861846446991, 0.11525630950927734, 0.11530232429504395, 0.11529533565044403, 0.11534644663333893, 0.11535728722810745, 0.11533760279417038, 0.11538084596395493, 0.11537732183933258, 0.11545740067958832, 0.11555399000644684, 0.1155683696269989, 0.11555769294500351, 0.11567950993776321, 0.11571049690246582, 0.11568769812583923, 0.1159062534570694, 0.11591388285160065, 0.11612294614315033, 0.1160494014620781, 0.11611603945493698, 0.1160973384976387, 0.11611025780439377, 0.11615637689828873, 0.11615775525569916, 0.11620882153511047, 0.11623982340097427, 0.11619341373443604, 0.11618601530790329, 0.11608466506004333, 0.11620589345693588, 0.11624101549386978, 0.11625578254461288, 0.11633215844631195, 0.1163940355181694, 0.11643007397651672, 0.1165301576256752, 0.1164553165435791, 0.11648815125226974, 0.11656614392995834, 0.11665169149637222, 0.11666932702064514, 0.11674048006534576, 0.11683907359838486, 0.11694461852312088, 0.11696106195449829, 0.11706209927797318, 0.11713699996471405, 0.1171894520521164, 0.11719927936792374, 0.11729307472705841, 0.11735887825489044, 0.11738212406635284, 0.11739684641361237, 0.11742650717496872, 0.11749626696109772, 0.11753088235855103, 0.11755728721618652, 0.11764979362487793, 0.11766771972179413, 0.11771643161773682, 0.1177503764629364, 0.117737777531147, 0.11773531883955002, 0.11770390719175339, 0.117825448513031, 0.11789677292108536, 0.1179322674870491, 0.11798258870840073, 0.1181916669011116, 0.11814839392900467, 0.11822722852230072, 0.1181626245379448, 0.11814052611589432, 0.11810749024152756, 0.11815975606441498, 0.1182452067732811, 0.11812731623649597, 0.1182207241654396, 0.11838328093290329, 0.1185755580663681, 0.11858560889959335, 0.11861743777990341, 0.11872247606515884, 0.11875420808792114, 0.11883678287267685, 0.118846096098423, 0.11873623728752136, 0.11879897117614746, 0.11887143552303314, 0.11888416856527328, 0.11911912262439728, 0.11916680634021759, 0.11916661262512207, 0.11918150633573532, 0.11937430500984192, 0.11929261684417725, 0.11926078796386719, 0.11933936923742294, 0.11940193176269531, 0.11944030970335007, 0.11954177916049957, 0.11949051171541214, 0.11951442062854767, 0.11960083246231079, 0.1197071298956871, 0.11971842497587204, 0.11980380862951279, 0.11982467025518417, 0.11986541748046875, 0.11993121355772018, 0.11994531750679016, 0.11997220665216446, 0.11995748430490494, 0.12006156146526337, 0.12013517320156097, 0.12015142291784286, 0.1201929897069931, 0.12026195973157883, 0.12021763622760773, 0.12028632313013077, 0.12031769007444382, 0.12053621560335159, 0.12052768468856812, 0.12060754746198654, 0.12064183503389359, 0.12068968266248703, 0.12076254189014435, 0.12082503736019135, 0.12087894976139069, 0.12089189887046814, 0.12073877453804016, 0.12074210494756699, 0.12067370116710663, 0.1206727921962738, 0.120712511241436, 0.12078404426574707, 0.12083873152732849, 0.12095266580581665, 0.12102487683296204, 0.1210191398859024, 0.12104856222867966, 0.12106790393590927, 0.12120649218559265, 0.12128255516290665, 0.12129741907119751, 0.12131981551647186, 0.12105298042297363, 0.12108874320983887, 0.12115103006362915, 0.12113048136234283, 0.12116921693086624, 0.12123370170593262, 0.12130817770957947, 0.12139003723859787, 0.12147879600524902, 0.12149666994810104, 0.12154200673103333, 0.12162904441356659, 0.12171543389558792, 0.12175165861845016, 0.1217912808060646, 0.12187187373638153, 0.12185817956924438, 0.12185745686292648, 0.12190824002027512, 0.12198556214570999, 0.12202776223421097, 0.12197542935609818, 0.12206461280584335, 0.12193945795297623, 0.12202546000480652, 0.1220584511756897, 0.12211053818464279, 0.12215382605791092, 0.12216867506504059, 0.12221676856279373, 0.12225660681724548, 0.1223321259021759, 0.12216237932443619, 0.12221026420593262, 0.1223432719707489, 0.12241989374160767, 0.12248227745294571, 0.12248175591230392, 0.12254362553358078, 0.12266014516353607, 0.1227567046880722, 0.12279938906431198, 0.1228138878941536, 0.12280698865652084, 0.12283387035131454, 0.12287291139364243, 0.12284237146377563, 0.12284091114997864, 0.12294081598520279, 0.12293709814548492, 0.12306710332632065, 0.12310074269771576, 0.12315517663955688, 0.12323176115751266, 0.12326263636350632, 0.12322897464036942, 0.12326490134000778, 0.12326617538928986, 0.12332908809185028, 0.12328018993139267, 0.12329758703708649, 0.12324606627225876, 0.12335622310638428, 0.12341184914112091, 0.12324312329292297, 0.1233791932463646, 0.12341319024562836, 0.1234259232878685, 0.12352436035871506, 0.1235818862915039, 0.12365217506885529, 0.12367264181375504, 0.12373867630958557, 0.12367655336856842, 0.12375566363334656, 0.12383827567100525, 0.12388520687818527, 0.12376364320516586, 0.12389775365591049, 0.12413672357797623, 0.12418469041585922, 0.12422899156808853, 0.12420476227998734, 0.12429105490446091, 0.12439096719026566, 0.12445001304149628, 0.12441956996917725, 0.1244826689362526, 0.12452170252799988, 0.12449853867292404, 0.12457914650440216, 0.12461400032043457, 0.12470149248838425, 0.12474684417247772, 0.12476789206266403, 0.12472905963659286, 0.12472943216562271, 0.12475042790174484, 0.12479114532470703, 0.12477996200323105, 0.1248452216386795, 0.12483171373605728, 0.12489429861307144, 0.1248442605137825, 0.12487966567277908, 0.12487848848104477, 0.12496370822191238, 0.12500281631946564, 0.12508094310760498, 0.12517091631889343, 0.12512777745723724, 0.12522321939468384, 0.12529782950878143, 0.12531717121601105, 0.12533578276634216, 0.12517349421977997, 0.1253804862499237, 0.12536709010601044, 0.12540924549102783, 0.12547431886196136, 0.12559671700000763, 0.1256643831729889, 0.12565015256404877, 0.12564602494239807, 0.12567918002605438, 0.12571687996387482, 0.12577912211418152, 0.12579120695590973, 0.1257835030555725, 0.12577468156814575, 0.12578922510147095, 0.12583574652671814, 0.12591129541397095, 0.12584765255451202, 0.1259586662054062, 0.126007080078125, 0.12604163587093353, 0.12604190409183502, 0.12606137990951538, 0.12610657513141632, 0.12613937258720398, 0.1261889636516571, 0.12618684768676758, 0.126262828707695, 0.12630556523799896, 0.12629559636116028, 0.12638555467128754, 0.1264004111289978, 0.12645970284938812, 0.12655691802501678, 0.12671783566474915, 0.1267128437757492, 0.12648150324821472, 0.12651434540748596, 0.12651978433132172, 0.12646353244781494, 0.12648387253284454, 0.12650643289089203, 0.1265072524547577, 0.12661625444889069, 0.12665681540966034, 0.1266828179359436, 0.12673546373844147, 0.1268233060836792, 0.12686754763126373, 0.12692031264305115, 0.12697839736938477, 0.12700478732585907, 0.12707297503948212, 0.12715235352516174, 0.1271025538444519, 0.12692362070083618, 0.12693791091442108, 0.12702007591724396, 0.12710227072238922, 0.12715519964694977, 0.12719827890396118, 0.12722405791282654, 0.12729370594024658, 0.1273564100265503, 0.12735536694526672, 0.12736853957176208, 0.1274532675743103, 0.1274794489145279, 0.12753978371620178, 0.12754781544208527, 0.12755413353443146, 0.12762480974197388, 0.12763601541519165, 0.12758304178714752, 0.1276196837425232, 0.12760193645954132, 0.12758132815361023, 0.12761375308036804, 0.1276092678308487, 0.1276477724313736, 0.12765511870384216, 0.127618208527565, 0.1277109980583191, 0.12770244479179382, 0.12774214148521423, 0.1277218908071518, 0.12775281071662903, 0.12784118950366974, 0.12787644565105438, 0.12799009680747986, 0.12800762057304382, 0.12798623740673065, 0.12788879871368408, 0.12785252928733826, 0.1278630495071411, 0.1279515027999878, 0.12798593938350677, 0.1280016303062439, 0.12802331149578094]\n",
      "feature_sparsity_history [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]\n",
      "feature_sparsity 26\n"
     ]
    }
   ],
   "source": [
    "constant_batch_size = 16\n",
    "batch_size_scaler = 1\n",
    "batch_size = constant_batch_size*batch_size_scaler\n",
    "constant_learning_rate = 0.1\n",
    "early_stopping = False\n",
    "\n",
    "\n",
    "num_train_samples = x_train.shape[0]\n",
    "epochs = 1000\n",
    "\n",
    "if num_train_samples % batch_size == 0:\n",
    "    epoch_step = num_train_samples / batch_size\n",
    "else:\n",
    "    epoch_step = int(num_train_samples / batch_size) + 1\n",
    "\n",
    "#         epochs = trial.suggest_int('epochs_new', 5, epochs)\n",
    "print(\"==============No LR scheduler, Epochs:\", epochs, \"Batch-size:\", batch_size)\n",
    "print(\"==============epochs:\", epochs)\n",
    "learning_rate = constant_learning_rate\n",
    "lr_schedule = utils.ConstantLearningRate(\n",
    "    learning_rate\n",
    ")\n",
    "optim = tf.keras.optimizers.SGD(lr_schedule)\n",
    "\n",
    "### Soft Decision Tree parameters \n",
    "num_trees = 20\n",
    "depth = 4\n",
    "\n",
    "activation = tf.keras.activations.sigmoid\n",
    "\n",
    "use_annealing = True\n",
    "kernel_constraint = 100\n",
    "temperature = 0.01\n",
    "kernel_l2 = 0.1\n",
    "kernel_l2 = kernel_l2/(num_trees*(2**depth - 1))\n",
    "kernel_regularizer = tf.keras.regularizers.L2(kernel_l2)\n",
    "if use_annealing:\n",
    "    kernel_constraint = kernel_constraint/num_features\n",
    "    temperature = temperature\n",
    "    kernel_constraint=sparse_soft_trees.ProximalGroupL0(lr=lr_schedule, lam=kernel_constraint, temperature=temperature, use_annealing=True, name='ProximalGroupL0')\n",
    "else:\n",
    "    kernel_constraint = kernel_constraint/num_features\n",
    "    kernel_constraint=sparse_soft_trees.ProximalGroupL0(lr=lr_schedule, lam=kernel_constraint, use_annealing=False, name='ProximalGroupL0')\n",
    "print(\"===========kernel_regularizer:\", kernel_regularizer)\n",
    "print(\"===========kernel_constraint:\", kernel_constraint)\n",
    "\n",
    "\n",
    "### Optimization parameters\n",
    "leaf_dims = (num_classes, )\n",
    "x = tf.keras.layers.Input(name='input', shape=x_train_processed.shape[1:])\n",
    "submodel = models.create_model(\n",
    "    x,\n",
    "    num_trees,\n",
    "    depth,\n",
    "    leaf_dims,\n",
    "    activation=activation,\n",
    "    kernel_regularizer=kernel_regularizer,\n",
    "    kernel_constraint=kernel_constraint,\n",
    ")\n",
    "x = submodel.input\n",
    "outputs = submodel(x)\n",
    "# print(outputs)\n",
    "ypred = tf.keras.layers.Activation('linear')(outputs)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model = tf.keras.Model(inputs=x, outputs=ypred)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "monitor = 'val_accuracy'\n",
    "metrics = ['accuracy']\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "cb = sparse_soft_trees.SparsityHistory()\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TerminateOnNaN(),\n",
    "    cb\n",
    "]    \n",
    "if early_stopping:\n",
    "    callbacks.append(\n",
    "        sparse_soft_trees.EarlyStopping(\n",
    "            config['cardinality'], monitor=monitor, patience=100, verbose=1, mode='auto', restore_best_weights=True\n",
    "        ),\n",
    "    )\n",
    "# print(\"====================y.shape\", data_processed.y_train_processed.shape)\n",
    "if len(get_available_gpus())==0:\n",
    "    history = model.fit(x=x_train_processed, \n",
    "              y=y_train_processed,\n",
    "              epochs=epochs, \n",
    "              batch_size=batch_size, \n",
    "              shuffle=True,\n",
    "              callbacks=callbacks,\n",
    "              validation_data=(x_valid_processed, y_valid_processed),\n",
    "              verbose=1, \n",
    "              )  \n",
    "else:\n",
    "    with tf.device(get_available_gpus()[0]):\n",
    "        history = model.fit(x=x_train_processed, \n",
    "                  y=y_train_processed,\n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  shuffle=True,\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=(x_valid_processed, y_valid_processed),\n",
    "                  verbose=0, \n",
    "                  )  \n",
    "number_of_epochs_it_ran = len(history.history['loss'])\n",
    "\n",
    "val_loss_history = history.history['val_loss']\n",
    "\n",
    "if early_stopping:\n",
    "    best_epoch = callbacks[-1].best_epoch # np.argmin(val_loss_history) + 1\n",
    "else:\n",
    "    best_epoch = len(val_loss_history)\n",
    "print(\"============best_epoch:\", best_epoch)\n",
    "print(\"============number_of_epochs_it_ran:\", number_of_epochs_it_ran)\n",
    "\n",
    "feature_sparsity_history = cb.selected_features[1:(best_epoch+1)]\n",
    "approximate_feature_sparsity_history = cb.approximately_selected_features[1:(best_epoch+1)]\n",
    "\n",
    "with tf.device(get_available_cpus()[0]):\n",
    "    # Check for infinite loss\n",
    "    training_loss = model.evaluate(x_train_processed,\n",
    "                                   y_train_processed,\n",
    "                                   batch_size=batch_size,\n",
    "                                   verbose=0)\n",
    "\n",
    "    if np.isfinite(np.sum(training_loss)) or ~np.isnan(np.sum(training_loss)):\n",
    "        # Evaluation\n",
    "\n",
    "        y_valid_pred = model.predict(x_valid_processed)\n",
    "        y_valid_prob = tf.nn.softmax(y_valid_pred, axis=1).numpy()\n",
    "        y_valid_pred_classes = np.argmax(y_valid_prob, axis=1)\n",
    "        classes = np.shape(y_valid_prob)[1]\n",
    "        if classes==2:\n",
    "            y_valid_prob = tf.gather(y_valid_prob, indices=[1], axis=1).numpy()\n",
    "        accuracy_valid = accuracy_score(y_valid_processed, y_valid_pred_classes)\n",
    "        auc_valid = roc_auc_score(\n",
    "            y_valid_processed,\n",
    "            y_valid_prob,\n",
    "            multi_class='ovo'\n",
    "        )\n",
    "\n",
    "        y_test_pred = model.predict(x_test_processed)\n",
    "        y_test_prob = tf.nn.softmax(y_test_pred, axis=1).numpy()\n",
    "        y_test_pred_classes = np.argmax(y_test_prob, axis=1)\n",
    "        if classes==2:\n",
    "            y_test_prob = tf.gather(y_test_prob, indices=[1], axis=1).numpy()\n",
    "        accuracy_test = accuracy_score(y_test_processed, y_test_pred_classes)\n",
    "        auc_test = roc_auc_score(\n",
    "            y_test_processed,\n",
    "            y_test_prob,\n",
    "            multi_class='ovo'\n",
    "        )\n",
    "        print('accuracy (valid):', accuracy_valid)\n",
    "        print('accuracy (test):', accuracy_test)\n",
    "        print('auc (valid):', auc_valid)\n",
    "        print('auc (test):', auc_test)\n",
    "print(\"num_epochs\", number_of_epochs_it_ran)\n",
    "print(\"val_loss_history\", val_loss_history)\n",
    "print(\"feature_sparsity_history\", feature_sparsity_history)    \n",
    "print(\"feature_sparsity\", feature_sparsity_history[-1])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968af4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-MOETF29]",
   "language": "python",
   "name": "conda-env-.conda-MOETF29-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
